{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b486c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9685030",
   "metadata": {},
   "source": [
    "# Understanding PyTorch `nn.Module` \n",
    "\n",
    "This code shows how to define a custom neural network model using PyTorch’s `nn.Module` class. It also demonstrates various model-related methods such as parameter registration, buffer registration, and mode switching.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ec812",
   "metadata": {},
   "source": [
    "## Base Classes\n",
    "They form the foudation of `Pytorch's Neural Network's` building blocks and utilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656a817",
   "metadata": {},
   "source": [
    "## Module\n",
    "### Code: `nn.module`\n",
    "### Common Parameters And Attributes:\n",
    "\n",
    "| Attribute/Method           | Type   | Description                                                   |\n",
    "|----------------------------|--------|---------------------------------------------------------------|\n",
    "| `.training`                | bool   | Indicates whether the model is in training mode.              |\n",
    "| `.forward()`               | method | Define the forward computation of your model.                 |\n",
    "| `.parameters()`            | method | Return an iterator over trainable parameters.                 |\n",
    "| `.children()`              | method | Yields immediate child modules.                               |\n",
    "| `.modules()`               | method | Recursively yields all modules.                               |\n",
    "| `.state_dict()`            | method | Returns a dictionary of model's learnable parameters.         |\n",
    "| `.load_state_dict()`       | method | Loads the state dict into the model.                          |\n",
    "| `.register_buffer(name, tensor)` | method | Registers a buffer (non-trainable tensor, like running stats). |\n",
    "| `.register_parameter(name, param)` | method | Register a parameter manually.                                 |\n",
    "| `.add_module(name, module)` | method | Adds a submodule manually.                                    |\n",
    "| `.to(device)`              | method | Moves model and parameters to a device.                       |\n",
    "| `.eval()` / `.train()`    | method | Switches between evaluation and training mode.                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb29f31",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37e61a",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Defining a Custom Model Class\n",
    "\n",
    "```\n",
    "class MyModel(nn.Module):\n",
    "```\n",
    "Here, We are creating a new neural network class that inherits from `nn.Module`, the base class for all Pytorch models.\n",
    "\n",
    "### Inside `__init__`: Defining the Layers\n",
    "\n",
    "```\n",
    "def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(MyModel, self).__init__()\n",
    "```\n",
    "- `input_size:` Number of features in the input.\n",
    "- `hidden_size:` Number of neurons in the hidden layer.\n",
    "- `output_size:` Number of output units.\n",
    "\n",
    "### Manual adding of Three Layers:\n",
    "```\n",
    "self.add_module('fc1', nn.Linear(input_size, hidden_size))\n",
    "self.add_module('relu', nn.ReLU())\n",
    "self.add_module('fc2', nn.Linear(hidden_size, output_size))\n",
    "```\n",
    "\n",
    "- `fc1:` Fully connected layer from input to hidden.\n",
    "- `relu:` ReLU activation Function.\n",
    "- `fc2:` Fully Connected layer from hidden to Output\n",
    "\n",
    "Using `.add_module()` allows you to add layers with custom names explicilty.\n",
    "\n",
    "### Alternative:\n",
    "```\n",
    "self.fc1= nn.Linear(...)\n",
    "```\n",
    "\n",
    "### Registering a Buffer:\n",
    "\n",
    "```\n",
    "self.register_buffer('running_mean', torch.zeros(output_size))\n",
    "\n",
    "```\n",
    "- Buffers are non-trainable tensors (not updated during backpropagation).\n",
    "- Common use: storing running statistics (like in BatchNorm).\n",
    "- Here we are creating `running_mean` tensor filled with zeros.\n",
    "\n",
    "`running_mean:`  <a href='#'> Wil be added</a>\n",
    "\n",
    "### Registering a Custom Parameter\n",
    "\n",
    "```\n",
    "param = nn.Parameter(torch.randn(output_size), requires_grad=True)\n",
    "self.register_parameter('custom_param', param)\n",
    "```\n",
    "\n",
    "- This creates a trainable tensor, not tied to specific layer.\n",
    "- `nn.Parameter` makes sure it's included in `.parameters()`.\n",
    "- `register_parameter()` adds it to the model manually.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5061243",
   "metadata": {},
   "source": [
    "## 3. Defining the Forward Pass\n",
    "\n",
    "```\n",
    "def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "```\n",
    "\n",
    "- This defines how the input `x` flows through the model.\n",
    "- Layers are applied in sequence: Linear -> ReLU -> Linear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c0f8a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. Using the model\n",
    "\n",
    "###  Instantiate the Model\n",
    "\n",
    "```\n",
    "model = MyModel(input_size=4, hidden_size=8, output_size=2)\n",
    "```\n",
    "Creates an instance of your model with specified dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "### Move to GPU or CPU\n",
    "\n",
    "```\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "```\n",
    "- Moves model to a GPU (if available) for faster computation.\n",
    "- Otherwise, it stays on the CPU.\n",
    "\n",
    "---\n",
    "\n",
    "### Set to Training Mode\n",
    "\n",
    "```\n",
    "model.train()\n",
    "print(f\"In training mode? {model.training}\")\n",
    "```\n",
    "\n",
    "- `.train()` enables training behaviors (e.g., Dropout, BatchNorm).\n",
    "- `model.training` returns `True` when in training mode.\n",
    "\n",
    "---\n",
    "\n",
    "### Dummy Input + Forward Pass\n",
    "\n",
    "```\n",
    "x = torch.randn(1, 4).to(device)\n",
    "output = model(x)\n",
    "print(\"Output:\", output)\n",
    "```\n",
    "- Creates a random input tensor with 4 features.\n",
    "- Passes it through the model.\n",
    "\n",
    "---\n",
    "\n",
    "###  Inspect Parameters\n",
    "\n",
    "```\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n",
    "```\n",
    "\n",
    "- Lists all trainable parameters, including manually registered ones.\n",
    "- Each parameter’s name and shape is printed.\n",
    "\n",
    "---\n",
    "\n",
    "### List Layers (Children)\n",
    "\n",
    "```\n",
    "for child in model.children():\n",
    "    print(child)\n",
    "```\n",
    "- `.children()` returns immediate child module(not nested ones).\n",
    "\n",
    "---\n",
    "\n",
    "### List All modules(Recursively)\n",
    "\n",
    "```\n",
    "for module in model.modules():\n",
    "    print(module)\n",
    "```\n",
    "Lists all submodules, including nested ones and the model itself.\n",
    "\n",
    "---\n",
    "\n",
    "### Save Model State\n",
    "\n",
    "```\n",
    "state = model.state_dict()\n",
    "print(state.keys())\n",
    "```\n",
    "- `.state_dict()` returns a dictionary of all learnable parameters and buffers.\n",
    "- You can use this to save your model later.\n",
    "\n",
    "---\n",
    "\n",
    "###  Load Model State\n",
    "\n",
    "```\n",
    "model.load_state_dict(state)\n",
    "```\n",
    "Load saved parameters back into the model.\n",
    "\n",
    "---\n",
    "\n",
    "### Switch to Evaluation Mode\n",
    "\n",
    "```\n",
    "model.eval()\n",
    "print(model.training)\n",
    "```\n",
    "- `.eval()` switches the model to evaluation mode (e.g., disables Dropout).\n",
    "- `model.training` will now return False.\n",
    "\n",
    "---\n",
    "\n",
    "### Access Buffer & Custom Parameter\n",
    "\n",
    "```\n",
    "print(model.running_mean)\n",
    "print(model.custom_param)\n",
    "```\n",
    "- `running_mean` is the registered buffer.\n",
    "- `custom_param` is the manually added trainable parameter.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c405d",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec13c618",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        # Add modules manually\n",
    "        self.add_module('fc1', nn.Linear(input_size, hidden_size))\n",
    "        self.add_module('relu', nn.ReLU())\n",
    "        self.add_module('fc2', nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        # Register a buffer (e.g. running mean – not a parameter)\n",
    "        self.register_buffer('running_mean', torch.zeros(output_size))\n",
    "\n",
    "        # Register a custom parameter (manually)\n",
    "        param = nn.Parameter(torch.randn(output_size), requires_grad=True)\n",
    "        self.register_parameter('custom_param', param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass using manually added modules\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d09bac",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training mode? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MyModel(input_size=4, hidden_size=8, output_size=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "print(f\"In training mode? {model.training}\")\n",
    "\n",
    "x = torch.randn(1, 4).to(device)\n",
    "\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a89b3cc",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[-0.1096, -0.0187]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Trainable Parameters:\n",
      "custom_param: torch.Size([2])\n",
      "fc1.weight: torch.Size([8, 4])\n",
      "fc1.bias: torch.Size([8])\n",
      "fc2.weight: torch.Size([2, 8])\n",
      "fc2.bias: torch.Size([2])\n",
      "\n",
      "Immediate Children:\n",
      "Linear(in_features=4, out_features=8, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=8, out_features=2, bias=True)\n",
      "\n",
      "All Modules:\n",
      "MyModel(\n",
      "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n",
      "Linear(in_features=4, out_features=8, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=8, out_features=2, bias=True)\n",
      "\n",
      "State Dict Keys:\n",
      "odict_keys(['custom_param', 'running_mean', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n",
      "\n",
      "In training mode after .eval()? False\n",
      "\n",
      "Registered Buffer:\n",
      "tensor([0., 0.])\n",
      "\n",
      "Custom Registered Parameter:\n",
      "Parameter containing:\n",
      "tensor([-0.1846, -0.4407], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Output:\", output)\n",
    "\n",
    "print(\"\\nTrainable Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n",
    "\n",
    "print(\"\\nImmediate Children:\")\n",
    "for child in model.children():\n",
    "    print(child)\n",
    "\n",
    "print(\"\\nAll Modules:\")\n",
    "for module in model.modules():\n",
    "    print(module)\n",
    "\n",
    "state = model.state_dict()\n",
    "print(\"\\nState Dict Keys:\")\n",
    "print(state.keys())\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print(f\"\\nIn training mode after .eval()? {model.training}\")\n",
    "\n",
    "print(\"\\nRegistered Buffer:\")\n",
    "print(model.running_mean)\n",
    "\n",
    "print(\"\\nCustom Registered Parameter:\")\n",
    "print(model.custom_param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
